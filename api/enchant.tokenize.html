

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>enchant.tokenize: String tokenization functions for PyEnchant &mdash; PyEnchant 3.3.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=3eb8911e"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="enchant.utils: Misc utilities for the enchant package" href="enchant.utils.html" />
    <link rel="prev" title="enchant.errors: Error class definitions for the enchant library" href="enchant.errors.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PyEnchant
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Listing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#full-list">Full list</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#by-module">By module</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="enchant.html">enchant:  Access to the enchant spellchecking library</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.Broker"><code class="docutils literal notranslate"><span class="pre">Broker</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.Dict"><code class="docutils literal notranslate"><span class="pre">Dict</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.DictWithPWL"><code class="docutils literal notranslate"><span class="pre">DictWithPWL</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.ProviderDesc"><code class="docutils literal notranslate"><span class="pre">ProviderDesc</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.dict_exists"><code class="docutils literal notranslate"><span class="pre">dict_exists()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.get_enchant_version"><code class="docutils literal notranslate"><span class="pre">get_enchant_version()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.get_param"><code class="docutils literal notranslate"><span class="pre">get_param()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.get_user_config_dir"><code class="docutils literal notranslate"><span class="pre">get_user_config_dir()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.list_dicts"><code class="docutils literal notranslate"><span class="pre">list_dicts()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.list_languages"><code class="docutils literal notranslate"><span class="pre">list_languages()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.request_dict"><code class="docutils literal notranslate"><span class="pre">request_dict()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.request_pwl_dict"><code class="docutils literal notranslate"><span class="pre">request_pwl_dict()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.set_param"><code class="docutils literal notranslate"><span class="pre">set_param()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.html#enchant.set_prefix_dir"><code class="docutils literal notranslate"><span class="pre">set_prefix_dir()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.checker.html">enchant.checker:  High-level spellchecking functionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.checker.html#enchant.checker.SpellChecker"><code class="docutils literal notranslate"><span class="pre">SpellChecker</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.errors.html">enchant.errors:  Error class definitions for the enchant library</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.errors.html#enchant.errors.DefaultLanguageNotFoundError"><code class="docutils literal notranslate"><span class="pre">DefaultLanguageNotFoundError</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.errors.html#enchant.errors.DictNotFoundError"><code class="docutils literal notranslate"><span class="pre">DictNotFoundError</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.errors.html#enchant.errors.Error"><code class="docutils literal notranslate"><span class="pre">Error</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.errors.html#enchant.errors.TokenizerNotFoundError"><code class="docutils literal notranslate"><span class="pre">TokenizerNotFoundError</span></code></a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">enchant.tokenize:    String tokenization functions for PyEnchant</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.Chunker"><code class="docutils literal notranslate"><span class="pre">Chunker</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.EmailFilter"><code class="docutils literal notranslate"><span class="pre">EmailFilter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.Filter"><code class="docutils literal notranslate"><span class="pre">Filter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.HTMLChunker"><code class="docutils literal notranslate"><span class="pre">HTMLChunker</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.HashtagFilter"><code class="docutils literal notranslate"><span class="pre">HashtagFilter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.MentionFilter"><code class="docutils literal notranslate"><span class="pre">MentionFilter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.URLFilter"><code class="docutils literal notranslate"><span class="pre">URLFilter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.WikiWordFilter"><code class="docutils literal notranslate"><span class="pre">WikiWordFilter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.basic_tokenize"><code class="docutils literal notranslate"><span class="pre">basic_tokenize</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.empty_tokenize"><code class="docutils literal notranslate"><span class="pre">empty_tokenize</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.get_tokenizer"><code class="docutils literal notranslate"><span class="pre">get_tokenizer()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.tokenize"><code class="docutils literal notranslate"><span class="pre">tokenize</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.unit_tokenize"><code class="docutils literal notranslate"><span class="pre">unit_tokenize</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#enchant.tokenize.wrap_tokenizer"><code class="docutils literal notranslate"><span class="pre">wrap_tokenizer()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.utils.html">enchant.utils:    Misc utilities for the enchant package</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.utils.html#enchant.utils.get_default_language"><code class="docutils literal notranslate"><span class="pre">get_default_language()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.utils.html#enchant.utils.levenshtein"><code class="docutils literal notranslate"><span class="pre">levenshtein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.utils.html#enchant.utils.trim_suggestions"><code class="docutils literal notranslate"><span class="pre">trim_suggestions()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.pypwl.html">pypwl:  pure-python personal word list in the style of Enchant</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.pypwl.html#enchant.pypwl.PyPWL"><code class="docutils literal notranslate"><span class="pre">PyPWL</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.pypwl.html#enchant.pypwl.Trie"><code class="docutils literal notranslate"><span class="pre">Trie</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../shootout.html">Provider Shootout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to PyEnchant</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyEnchant</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">API Listing</a></li>
      <li class="breadcrumb-item active">enchant.tokenize:    String tokenization functions for PyEnchant</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/enchant.tokenize.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="enchant-tokenize-string-tokenization-functions-for-pyenchant">
<span id="module-enchant.tokenize"></span><h1>enchant.tokenize:    String tokenization functions for PyEnchant<a class="headerlink" href="#enchant-tokenize-string-tokenization-functions-for-pyenchant" title="Link to this heading"></a></h1>
<p>An important task in spellchecking is breaking up large bodies of
text into their constituent words, each of which is then checked
for correctness.  This package provides Python functions to split
strings into words according to the rules of a particular language.</p>
<p>Each tokenization function accepts a string as its only positional
argument, and returns an iterator that yields tuples of the following
form, one for each word found:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="o">&lt;</span><span class="n">word</span><span class="o">&gt;</span><span class="p">,</span><span class="o">&lt;</span><span class="n">pos</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>The meanings of these fields should be clear: <cite>word</cite> is the word
that was found and <cite>pos</cite> is the position within the text at which
the word began (zero indexed, of course).  The function will work
on any string-like object that supports array-slicing; in particular
character-array objects from the <code class="xref py py-mod docutils literal notranslate"><span class="pre">array</span></code> module may be used.</p>
<p>The iterator also provides the attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">offset</span></code> which gives the current
position of the tokenizer inside the string being split, and the method
<code class="xref py py-meth docutils literal notranslate"><span class="pre">set_offset()</span></code> for manually adjusting this position.  This can be used for
example if the string’s contents have changed during the tokenization
process.</p>
<p>To obtain an appropriate tokenization function for the language
identified by <cite>tag</cite>, use the function <a class="reference internal" href="#enchant.tokenize.get_tokenizer" title="enchant.tokenize.get_tokenizer"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_tokenizer()</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tknzr</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;en_US&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tknzr</span><span class="p">(</span><span class="s2">&quot;text to be tokenized goes here&quot;</span><span class="p">)</span>
    <span class="n">do_something</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</pre></div>
</div>
<p>This library is designed to be easily extendible by third-party
authors.  To register a tokenization function for the language
<cite>tag</cite>, implement it as the function <cite>tokenize</cite> within the
module <cite>enchant.tokenize.&lt;tag&gt;</cite>.  The function <a class="reference internal" href="#enchant.tokenize.get_tokenizer" title="enchant.tokenize.get_tokenizer"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_tokenizer()</span></code></a>
will automatically detect it.  Note that the underscore must be
used as the tag component separator in this case, in order to
form a valid python module name. (e.g. “en_US” rather than “en-US”)</p>
<p>Currently, a tokenizer has only been implemented for the English
language.  Based on the author’s limited experience, this should
be at least partially suitable for other languages.</p>
<p>This module also provides various implementations of Chunkers and
Filters.  These classes are designed to make it easy to work with
text in a variety of common formats, by detecting and excluding parts
of the text that don’t need to be checked.</p>
<p>A <a class="reference internal" href="#enchant.tokenize.Chunker" title="enchant.tokenize.Chunker"><code class="xref py py-class docutils literal notranslate"><span class="pre">Chunker</span></code></a> is a class designed to break a body of text into large chunks
of checkable content; for example the <a class="reference internal" href="#enchant.tokenize.HTMLChunker" title="enchant.tokenize.HTMLChunker"><code class="xref py py-class docutils literal notranslate"><span class="pre">HTMLChunker</span></code></a> class extracts the
text content from all HTML tags but excludes the tags themselves.
A <a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Filter</span></code></a> is a class designed to skip individual words during the checking
process; for example the <a class="reference internal" href="#enchant.tokenize.URLFilter" title="enchant.tokenize.URLFilter"><code class="xref py py-class docutils literal notranslate"><span class="pre">URLFilter</span></code></a> class skips over any words that
have the format of a URL.</p>
<p>For example, to spellcheck an HTML document it is necessary to split the
text into chunks based on HTML tags, and to filter out common word forms
such as URLs and WikiWords.  This would look something like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tknzr</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;en_US&quot;</span><span class="p">,(</span><span class="n">HTMLChunker</span><span class="p">,),(</span><span class="n">URLFilter</span><span class="p">,</span><span class="n">WikiWordFilter</span><span class="p">)))</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&lt;html&gt;&lt;body&gt;the url is http://example.com&lt;/body&gt;&lt;/html&gt;&quot;</span>
<span class="k">for</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tknzer</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="o">...</span><span class="n">check</span> <span class="n">each</span> <span class="n">word</span> <span class="ow">and</span> <span class="n">react</span> <span class="n">accordingly</span><span class="o">...</span>
</pre></div>
</div>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.Chunker">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">Chunker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.Chunker" title="Link to this definition"></a></dt>
<dd><p>Base class for text chunking functions.</p>
<p>A chunker is designed to chunk text into large blocks of tokens.  It
has the same interface as a tokenizer but is for a different purpose.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.EmailFilter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">EmailFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.EmailFilter" title="Link to this definition"></a></dt>
<dd><p>Filter skipping over email addresses.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^.+&#64;[^.].*.[a-z]{2,}$</p>
</div></blockquote>
<p>That is, any words that resemble email addresses.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.Filter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">Filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.Filter" title="Link to this definition"></a></dt>
<dd><p>Base class for token filtering functions.</p>
<p>A filter is designed to wrap a tokenizer (or another <a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Filter</span></code></a>) and do
two things:</p>
<blockquote>
<div><ul class="simple">
<li><p>skip over tokens</p></li>
<li><p>split tokens into sub-tokens</p></li>
</ul>
</div></blockquote>
<p>Subclasses have two basic options for customising their behaviour.  The
method <code class="xref py py-meth docutils literal notranslate"><span class="pre">_skip()</span></code> may be overridden to return <cite>True</cite> for words that
should be skipped, and <cite>False</cite> otherwise.  The method <code class="xref py py-meth docutils literal notranslate"><span class="pre">_split()</span></code> may
be overridden as tokenization function that will be applied to further
tokenize any words that aren’t skipped.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.HTMLChunker">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">HTMLChunker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.HTMLChunker" title="Link to this definition"></a></dt>
<dd><p>Chunker for breaking up HTML documents into chunks of checkable text.</p>
<p>The operation of this chunker is very simple - anything between a “&lt;”
and a “&gt;” will be ignored.  Later versions may improve the algorithm
slightly.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.HashtagFilter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">HashtagFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.HashtagFilter" title="Link to this definition"></a></dt>
<dd><p>Filter skipping over #hashtag.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>(A|s)#(w+)</p>
</div></blockquote>
<p>That is, any words that are #hashtag.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.MentionFilter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">MentionFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.MentionFilter" title="Link to this definition"></a></dt>
<dd><p>Filter skipping over &#64;mention.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>(A|s)&#64;(w+)</p>
</div></blockquote>
<p>That is, any words that are &#64;mention.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.URLFilter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">URLFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.URLFilter" title="Link to this definition"></a></dt>
<dd><p>Filter skipping over URLs.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^[a-zA-Z]+://[^s].*</p>
</div></blockquote>
<p>That is, any words that are URLs.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.WikiWordFilter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">WikiWordFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.WikiWordFilter" title="Link to this definition"></a></dt>
<dd><p>Filter skipping over WikiWords.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^([A-Z]w+[A-Z]+w+)</p>
</div></blockquote>
<p>That is, any words that are WikiWords.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.basic_tokenize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">basic_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.basic_tokenize" title="Link to this definition"></a></dt>
<dd><p>Tokenizer class that performs very basic word-finding.</p>
<p>This tokenizer does the most basic thing that could work - it splits
text into words based on whitespace boundaries, and removes basic
punctuation symbols from the start and end of each word.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.empty_tokenize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">empty_tokenize</span></span><a class="headerlink" href="#enchant.tokenize.empty_tokenize" title="Link to this definition"></a></dt>
<dd><p>Tokenizer class that yields no elements.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="enchant.tokenize.get_tokenizer">
<span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">get_tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunkers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.Chunker" title="enchant.tokenize.Chunker"><span class="pre">Chunker</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a></span></span><a class="headerlink" href="#enchant.tokenize.get_tokenizer" title="Link to this definition"></a></dt>
<dd><p>Locate an appropriate tokenizer by language tag.</p>
<p>This requires importing the function <cite>tokenize</cite> from an appropriate
module.  Modules tried are named after the language tag, tried in the
following order:</p>
<blockquote>
<div><ul class="simple">
<li><p>the entire tag (e.g. “en_AU.py”)</p></li>
<li><p>the base country code of the tag (e.g. “en.py”)</p></li>
</ul>
</div></blockquote>
<p>If the language tag is <cite>None</cite>, a default tokenizer (actually the English
one) is returned.  It’s unicode aware and should work OK for most
latin-derived languages.</p>
<p>If a suitable function cannot be found, raises <a class="reference internal" href="enchant.errors.html#enchant.errors.TokenizerNotFoundError" title="enchant.errors.TokenizerNotFoundError"><code class="xref py py-exc docutils literal notranslate"><span class="pre">TokenizerNotFoundError</span></code></a>.</p>
<p>If given and not <cite>None</cite>, <cite>chunkers</cite> and <cite>filters</cite> must be lists of chunker
classes and filter classes respectively.  These will be applied to the
tokenizer during creation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.tokenize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.tokenize" title="Link to this definition"></a></dt>
<dd><p>Base class for all tokenizer objects.</p>
<p>Each tokenizer must be an iterator and provide the <code class="xref py py-attr docutils literal notranslate"><span class="pre">offset</span></code>
attribute as described in the documentation for this module.</p>
<p>While tokenizers are in fact classes, they should be treated
like functions, and so are named using lower_case rather than
the CamelCase more traditional of class names.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="enchant.tokenize.unit_tokenize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">unit_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.unit_tokenize" title="Link to this definition"></a></dt>
<dd><p>Tokenizer class that yields the text as a single token.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="enchant.tokenize.wrap_tokenizer">
<span class="sig-prename descclassname"><span class="pre">enchant.tokenize.</span></span><span class="sig-name descname"><span class="pre">wrap_tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tk1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tk2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#enchant.tokenize.tokenize" title="enchant.tokenize.tokenize"><span class="pre">tokenize</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#enchant.tokenize.Filter" title="enchant.tokenize.Filter"><span class="pre">Filter</span></a></span></span><a class="headerlink" href="#enchant.tokenize.wrap_tokenizer" title="Link to this definition"></a></dt>
<dd><p>Wrap one tokenizer inside another.</p>
<p>This function takes two tokenizer functions <cite>tk1</cite> and <cite>tk2</cite>,
and returns a new tokenizer function that passes the output
of <cite>tk1</cite> through <cite>tk2</cite> before yielding it to the calling code.</p>
</dd></dl>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="enchant.errors.html" class="btn btn-neutral float-left" title="enchant.errors: Error class definitions for the enchant library" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="enchant.utils.html" class="btn btn-neutral float-right" title="enchant.utils: Misc utilities for the enchant package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2011, Ryan Kelly.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>